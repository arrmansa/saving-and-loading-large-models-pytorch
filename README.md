# saving-and-loading-large-models-pytorch
 I am using this to load gpt-j-6b to prevent excessive ram usage
