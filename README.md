# saving-and-loading-large-models-pytorch
 I am using this to load gpt-j-6b and gpt-neo to prevent excessive ram usage
